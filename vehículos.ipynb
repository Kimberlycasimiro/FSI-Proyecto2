{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae82d9f1",
   "metadata": {},
   "source": [
    "### **Práctica 2: Conteo de vehículos que transitan en vías de tráfico**\n",
    "\n",
    "***Autores:** Mendoza Peña, Raúl y Casimiro Torres, Kimberly*\n",
    "\n",
    "<img src=\"./Imagen_conteo_vehiculos.png\" alt=\"Imagen con el conteo de vehículos realizado\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2eb761e",
   "metadata": {},
   "source": [
    "#### **Descripción del Proyecto**\n",
    "\n",
    "Este proyecto consiste en desarrollar un sistema que permita contar vehículos en un video de tráfico (`tráfico01.mp4`). El objetivo es detectar y contar vehículos que cruzan diferentes líneas de monitoreo, correspondientes a carriles o vías en el video."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bde4d3",
   "metadata": {},
   "source": [
    "#### **1. Importación de bibliotecas necesarias**\n",
    "\n",
    "Para este proyecto, utilizamos únicamente la biblioteca **`cv2`** de OpenCV.\n",
    "\n",
    "##### **¿Qué es OpenCV?**\n",
    "OpenCV es una biblioteca de código abierto muy popular para el procesamiento de imágenes y videos en tiempo real. Proporciona herramientas poderosas para detectar y rastrear objetos, realizar transformaciones en imágenes, manipular videos y más. En este proyecto, OpenCV se utiliza para:\n",
    "\n",
    "- Leer y procesar el video de tráfico (`tráfico01.mp4`).\n",
    "- Aplicar técnicas de segmentación para separar objetos en movimiento (vehículos) del fondo.\n",
    "- Detectar contornos y rastrear vehículos.\n",
    "- Visualizar los resultados en tiempo real dibujando líneas de monitoreo y mostrando conteos acumulados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088c1660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e77ed34",
   "metadata": {},
   "source": [
    "#### **2. Configuración del video**\n",
    "El video de tráfico que vamos a analizar se encuentra en un archivo llamado `tráfico01.mp4`. La ruta del archivo se define en la variable video_path. Este será el punto de partida para que OpenCV pueda cargar el video y procesarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde8b8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta del video proporcionado\n",
    "video_path = 'tráfico01.mp4'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea0f777",
   "metadata": {},
   "source": [
    "#### **3. Coordenadas de las líneas de monitoreo**\n",
    "Definimos un conjunto de líneas que sirven para monitorear diferentes carriles o vías en el video. Estas líneas se especifican mediante sus coordenadas en el espacio de píxeles del frame del video. Cada línea está representada por un diccionario con los siguientes valores:\n",
    "\n",
    "-  **x1, y1:** Coordenadas del punto inicial de la línea.\n",
    "-  **x2, y2:** Coordenadas del punto final de la línea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61bafdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordenadas de las líneas segmentadas (Vías y Carriles separados)\n",
    "lines_positions = [\n",
    "    {\"x1\": 480, \"y1\": 800, \"x2\": 570, \"y2\": 800},  # Vía 1\n",
    "    {\"x1\": 600, \"y1\": 800, \"x2\": 700, \"y2\": 800},  # Vía 2\n",
    "    {\"x1\": 990, \"y1\": 750, \"x2\": 1090, \"y2\": 750},  # Carril 1 -> Vía 3\n",
    "    {\"x1\": 1280, \"y1\": 890, \"x2\": 1500, \"y2\": 890},  # Carril 2 -> Vía 3\n",
    "    {\"x1\": 1200, \"y1\": 660, \"x2\": 1260, \"y2\": 660},  # Carril 3 -> Vía 4\n",
    "    {\"x1\": 1450, \"y1\": 750, \"x2\": 1550, \"y2\": 750},  # Carril 4 -> Vía 4\n",
    "    {\"x1\": 1650, \"y1\": 790, \"x2\": 1800, \"y2\": 790},  # Carril 5 -> Vía 4\n",
    "    {\"x1\": 1500, \"y1\": 450, \"x2\": 1800, \"y2\": 450},  # Vía 5\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695b81ee",
   "metadata": {},
   "source": [
    "Las coordenadas están ajustadas específicamente al video tráfico01.mp4 para que las líneas coincidan visualmente con las posiciones de los carriles y vías en el frame. Los valores se definen en píxeles, que es la unidad de medida en OpenCV para los frames de video. Estas líneas actúan como \"sensores\" virtuales para detectar el paso de vehículos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f4da18",
   "metadata": {},
   "source": [
    "#### **4: Configuración de parámetros para la detección de vehículos**\n",
    "En esta sección, configuramos los parámetros clave que controlan cómo se detectan y rastrean los vehículos en el video.\n",
    "\n",
    "##### Parámetros incluidos:\n",
    "1. **Umbrales mínimos de área**: Controlan el tamaño mínimo necesario para que un objeto sea considerado un vehículo.\n",
    "2. **Ancho máximo de vehículos**: Filtra objetos que excedan un tamaño razonable.\n",
    "3. **Listas y diccionarios para el conteo y seguimiento**: Incluyen contadores de vehículos, objetos rastreados y su tiempo de expiración.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fb8a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Umbrales mínimos de área y tamaños para cada carril\n",
    "area_thresholds = [400, 500, 700, 800, 700, 700, 500, 600]  # Configuración específica para cada carril\n",
    "\n",
    "# Ancho máximo permitido para un vehículo\n",
    "max_vehicle_width = 400  \n",
    "\n",
    "# Contadores para el número de vehículos detectados por carril\n",
    "vehicle_count = [0] * len(lines_positions)  # Lista de contadores inicializados en 0\n",
    "\n",
    "# Diccionarios para rastrear objetos detectados por carril\n",
    "tracked_objects = [{} for _ in range(len(lines_positions))]  # Lista de diccionarios vacíos\n",
    "\n",
    "# Identificadores únicos para los objetos detectados en cada carril\n",
    "object_ids = [0] * len(lines_positions)  # Inicializados en 0 para cada carril\n",
    "\n",
    "# Tiempo máximo que un objeto puede estar inactivo antes de considerarse \"expirado\"\n",
    "object_expiry = 16  # Definido en número de frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dc3990",
   "metadata": {},
   "source": [
    "#### **5: Función auxiliar para detectar cruces de líneas**\n",
    "Esta función verifica si un objeto detectado (representado por un punto) cruza una línea específica en el espacio de píxeles del video.\n",
    "\n",
    "##### Parámetros de entrada:\n",
    "1. **`cx`**: Coordenada X del centroide del objeto.\n",
    "2. **`cy`**: Coordenada Y del centroide del objeto.\n",
    "3. **`line`**: Diccionario que define una línea en el espacio de píxeles, con los campos:\n",
    "   - `x1`, `y1`: Coordenadas del punto inicial de la línea.\n",
    "   - `x2`, `y2`: Coordenadas del punto final de la línea.\n",
    "\n",
    "##### Salida:\n",
    "- Devuelve `True` si el centroide del objeto se encuentra dentro del rango horizontal de la línea (`x1` a `x2`) y si la distancia vertical al centroide desde la línea (`cy - y1`) es menor o igual a 10 píxeles.  \n",
    "- De lo contrario, devuelve `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d942a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crosses_line(cx, cy, line):  \n",
    "    # Define la función `crosses_line` para verificar si un objeto cruza una línea específica.\n",
    "\n",
    "    return line[\"x1\"] <= cx <= line[\"x2\"] and abs(cy - line[\"y1\"]) <= 10  \n",
    "    # Comprueba si el objeto está dentro del rango horizontal de la línea (`x1` <= `cx` <= `x2`)\n",
    "    # y si la distancia vertical entre el centro del objeto (`cy`) y la línea (`y1`) es menor o igual a 10 píxeles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f9deb3",
   "metadata": {},
   "source": [
    "#### **6. Carga del video y configuración del sustractor de fondo**\n",
    "En esta sección, cargamos el video proporcionado y configuramos el sustractor de fondo para detectar objetos en movimiento (vehículos).\n",
    "\n",
    "##### Pasos realizados:\n",
    "1. Abrimos el archivo de video con OpenCV.\n",
    "2. Verificamos si el video se ha cargado correctamente.\n",
    "3. Configuramos un **sustractor de fondo**, una herramienta que separa los objetos en movimiento del fondo estático.\n",
    "4. Parámetros del sustractor:\n",
    "    - *history=500*: Número de frames usados para construir el modelo del fondo.\n",
    "    - *varThreshold=50*: Sensibilidad para detectar cambios en los píxeles. Valores más bajos hacen que el modelo sea más sensible, mientras que valores más altos lo hacen menos sensible.\n",
    "    - *detectShadows=False*: Desactiva la detección de sombras para evitar falsos positivos.\n",
    "5. Inicializamos un contador de frames para rastrear el progreso del video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a83fcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(video_path)  \n",
    "# Abre el archivo de video especificado en la ruta `video_path` para procesarlo.\n",
    "\n",
    "if not cap.isOpened():  \n",
    "    # Verifica si el archivo de video se abrió correctamente.\n",
    "\n",
    "    print(\"Error: No se puede abrir el video.\")  \n",
    "    # Muestra un mensaje de error en caso de que el video no pueda abrirse.\n",
    "else:  \n",
    "    # Ejecuta este bloque si el archivo de video se abrió correctamente.\n",
    "\n",
    "    background_subtractor = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=50, detectShadows=False)  \n",
    "    # Configura un sustractor de fondo para detectar objetos en movimiento:\n",
    "    # - `history=500`: Usa los últimos 500 frames para construir el modelo del fondo.\n",
    "    # - `varThreshold=50`: Define la sensibilidad al cambio de píxeles (valores más bajos detectan más).\n",
    "    # - `detectShadows=False`: No considera sombras para evitar falsos positivos.\n",
    "\n",
    "    frame_count = 0  \n",
    "    # Inicializa el contador de frames en 0 para rastrear el progreso del video."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f24fea",
   "metadata": {},
   "source": [
    "#### **6. Procesamiento del video frame por frame**\n",
    "En esta sección, procesamos cada frame del video para detectar objetos en movimiento (vehículos) utilizando el sustractor de fondo configurado anteriormente. Este proceso incluye convertir los frames a escala de grises, aplicar el sustractor de fondo y extraer contornos de los objetos detectados.\n",
    "\n",
    "##### Pasos realizados:\n",
    "1. **Lectura del frame actual**: Se obtiene el siguiente frame del video.\n",
    "2. **Conversión a escala de grises**: Simplifica la imagen para el procesamiento.\n",
    "3. **Sustracción de fondo**: Detecta las diferencias entre el fondo estático y los objetos en movimiento.\n",
    "4. **Operaciones morfológicas**: Limpia la máscara de ruido o pequeños fragmentos.\n",
    "5. **Binarización**: Asegura que solo se detecten objetos relevantes.\n",
    "6. **Detección de contornos**: Identifica los límites de los objetos detectados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b0d0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:  \n",
    "    # Inicia un bucle infinito para procesar cada frame del video.\n",
    "\n",
    "    ret, frame = cap.read()  \n",
    "    # Lee el siguiente frame del video.\n",
    "    # `ret` indica si la lectura fue exitosa (True) o si se alcanzó el final (False).\n",
    "    # `frame` contiene los datos del frame actual.\n",
    "\n",
    "    if not ret:  \n",
    "        # Si no se pudo leer el frame (por ejemplo, al llegar al final del video):\n",
    "        break  \n",
    "        # Sale del bucle para detener el procesamiento.\n",
    "\n",
    "    frame_count += 1  \n",
    "    # Incrementa el contador de frames en 1 para rastrear el número de frames procesados.\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  \n",
    "    # Convierte el frame de color (BGR) a escala de grises para simplificar el procesamiento.\n",
    "\n",
    "    fg_mask = background_subtractor.apply(gray)  \n",
    "    # Aplica el sustractor de fondo al frame en escala de grises para detectar objetos en movimiento.\n",
    "\n",
    "    fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5)))  \n",
    "    # Aplica una operación de cierre (closing) para eliminar ruido y pequeños huecos en la máscara.\n",
    "\n",
    "    _, fg_mask = cv2.threshold(fg_mask, 254, 255, cv2.THRESH_BINARY)  \n",
    "    # Convierte la máscara en una imagen binaria (solo valores 0 y 255) para resaltar objetos detectados.\n",
    "\n",
    "    contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  \n",
    "    # Encuentra los contornos en la máscara binaria:\n",
    "    # - `cv2.RETR_EXTERNAL`: Obtiene solo los contornos externos (ignora los internos).\n",
    "    # - `cv2.CHAIN_APPROX_SIMPLE`: Reduce los puntos del contorno para ahorrar memoria.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25addf86",
   "metadata": {},
   "source": [
    "#### **7. Procesamiento de contornos y conteo de vehículos**\n",
    "En esta sección, procesamos los contornos detectados para identificar vehículos, determinar si cruzan las líneas de monitoreo y actualizar los contadores. Este análisis incluye:\n",
    "\n",
    "1. **Extracción de propiedades del contorno**: Calculamos el centroide y el tamaño del objeto.\n",
    "2. **Filtrado de objetos irrelevantes**: Eliminamos sombras y objetos pequeños.\n",
    "3. **Detección del carril correspondiente**: Verificamos si el objeto cruza alguna línea de monitoreo.\n",
    "4. **Rastreo de vehículos**: Identificamos objetos nuevos o actualizamos objetos existentes.\n",
    "5. **Actualización de contadores**: Incrementamos el conteo de vehículos cuando un nuevo objeto cruza la línea.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aabaf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "for contour in contours:  \n",
    "    # Itera sobre cada contorno detectado en la máscara binaria.\n",
    "\n",
    "    x, y, w, h = cv2.boundingRect(contour)  \n",
    "    # Calcula el rectángulo delimitador del contorno:\n",
    "    # - `x`, `y`: Coordenadas de la esquina superior izquierda.\n",
    "    # - `w`, `h`: Ancho y alto del rectángulo.\n",
    "\n",
    "    cx, cy = x + w // 2, y + h // 2  \n",
    "    # Calcula el centro del rectángulo delimitador (`cx`, `cy`).\n",
    "\n",
    "    if w > max_vehicle_width or cv2.contourArea(contour) < 500:  \n",
    "        # Filtra objetos irrelevantes:\n",
    "        # - Si el ancho del objeto excede `max_vehicle_width`, lo ignora.\n",
    "        # - Si el área del contorno es menor a 500 píxeles, también lo ignora.\n",
    "        continue  \n",
    "        # Salta al siguiente contorno.\n",
    "\n",
    "    for i, line in enumerate(lines_positions):  \n",
    "        # Itera sobre todas las líneas de monitoreo definidas.\n",
    "\n",
    "        if crosses_line(cx, cy, line):  \n",
    "            # Verifica si el centro del objeto cruza la línea actual.\n",
    "\n",
    "            if cv2.contourArea(contour) < area_thresholds[i]:  \n",
    "                # Verifica si el área del contorno es menor al umbral mínimo para esa línea.\n",
    "                # Si no cumple, el contorno se ignora.\n",
    "                continue  \n",
    "\n",
    "            new_object = True  \n",
    "            # Marca inicialmente el objeto como \"nuevo\".\n",
    "\n",
    "            for obj_id in list(tracked_objects[i].keys()):  \n",
    "                # Itera sobre los objetos ya rastreados en el carril correspondiente.\n",
    "\n",
    "                prev_cx, prev_cy, last_seen = tracked_objects[i][obj_id]  \n",
    "                # Recupera las coordenadas previas y el último frame donde fue visto el objeto.\n",
    "\n",
    "                if abs(cx - prev_cx) < 50 and abs(cy - prev_cy) < 50:  \n",
    "                    # Comprueba si el objeto actual está cerca de un objeto rastreado previamente\n",
    "                    # (dentro de un rango de 50 píxeles en ambas coordenadas).\n",
    "\n",
    "                    tracked_objects[i][obj_id] = (cx, cy, frame_count)  \n",
    "                    # Actualiza las coordenadas y el último frame visto del objeto rastreado.\n",
    "\n",
    "                    new_object = False  \n",
    "                    # Marca el objeto como \"no nuevo\" porque ya está siendo rastreado.\n",
    "                    break  \n",
    "\n",
    "            if new_object:  \n",
    "                # Si el objeto es realmente nuevo:\n",
    "                tracked_objects[i][object_ids[i]] = (cx, cy, frame_count)  \n",
    "                # Lo agrega a la lista de objetos rastreados para el carril correspondiente.\n",
    "\n",
    "                vehicle_count[i] += 1  \n",
    "                # Incrementa el conteo de vehículos en el carril correspondiente.\n",
    "\n",
    "                object_ids[i] += 1  \n",
    "                # Actualiza el próximo identificador único disponible para objetos nuevos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1811158a",
   "metadata": {},
   "source": [
    "#### **8. Limpieza de objetos expirados y visualización de resultados**\n",
    "En esta sección, realizamos dos tareas principales:\n",
    "\n",
    "1. **Limpieza de objetos expirados**: Eliminamos del rastreo aquellos objetos que no han sido detectados en un tiempo prolongado (basado en el número de frames).\n",
    "2. **Visualización de resultados**: Dibujamos las líneas de monitoreo y mostramos el conteo acumulado de vehículos directamente sobre los frames procesados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb9f7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, _ in enumerate(lines_positions):  \n",
    "    # Itera sobre cada línea de monitoreo definida en `lines_positions`.\n",
    "\n",
    "    expired_ids = [  \n",
    "        # Crea una lista de identificadores (`expired_ids`) para los objetos que han expirado.\n",
    "\n",
    "        obj_id for obj_id, (_, _, last_seen) in tracked_objects[i].items()  \n",
    "        # Recorre todos los objetos rastreados (`tracked_objects[i]`) en el carril actual.\n",
    "        # Extrae el identificador del objeto (`obj_id`) y el último frame en el que fue visto (`last_seen`).\n",
    "\n",
    "        if frame_count - last_seen > object_expiry  \n",
    "        # Comprueba si el tiempo transcurrido desde el último frame en que se vio el objeto\n",
    "        # excede el límite (`object_expiry`). Si es así, el objeto se considera expirado.\n",
    "    ]\n",
    "\n",
    "    for obj_id in expired_ids:  \n",
    "        # Itera sobre los identificadores de los objetos expirados.\n",
    "\n",
    "        del tracked_objects[i][obj_id]  \n",
    "        # Elimina cada objeto expirado del diccionario de objetos rastreados.\n",
    "\n",
    "    for i, line in enumerate(lines_positions):  \n",
    "        # Itera nuevamente sobre todas las líneas de monitoreo.\n",
    "\n",
    "        if 2 <= i <= 6:  \n",
    "            # Comprueba si el índice de la línea está entre 2 y 6 (corresponde a carriles específicos).\n",
    "\n",
    "            label = f\"Carril {i - 1}: {vehicle_count[i]}\"  \n",
    "            # Asigna una etiqueta que muestra el conteo de vehículos para los carriles.\n",
    "        else:  \n",
    "            # Si la línea no está entre los índices 2 y 6, se trata de una vía completa.\n",
    "\n",
    "            label = f\"Via {i + 1}: {vehicle_count[i]}\"  \n",
    "            # Asigna una etiqueta que muestra el conteo de vehículos para las vías.\n",
    "\n",
    "        cv2.line(frame, (line[\"x1\"], line[\"y1\"]), (line[\"x2\"], line[\"y2\"]), (0, 255, 0), 2)  \n",
    "        # Dibuja la línea de monitoreo en el frame:\n",
    "        # - Usa las coordenadas (`x1`, `y1`, `x2`, `y2`) de la línea actual.\n",
    "        # - Color: verde `(0, 255, 0)`.\n",
    "        # - Grosor: 2 píxeles.\n",
    "\n",
    "        cv2.putText(frame, label, (line[\"x1\"], line[\"y1\"] - 20),  \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)  \n",
    "        # Dibuja la etiqueta con el conteo de vehículos encima de la línea:\n",
    "        # - Texto: el valor de `label`.\n",
    "        # - Posición: ligeramente encima de la línea (`line[\"y1\"] - 20`).\n",
    "        # - Fuente: `cv2.FONT_HERSHEY_SIMPLEX`.\n",
    "        # - Tamaño de fuente: 0.6.\n",
    "        # - Color: blanco `(255, 255, 255)`.\n",
    "        # - Grosor del texto: 2 píxeles.\n",
    "\n",
    "    cv2.imshow(\"Vehicle Counting\", frame)  \n",
    "    # Muestra el frame procesado en una ventana llamada \"Vehicle Counting\".\n",
    "\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):  \n",
    "        # Espera 30 milisegundos para detectar si se presiona una tecla.\n",
    "        # Si la tecla presionada es `q`, sale del bucle.\n",
    "\n",
    "        break  \n",
    "        # Rompe el bucle para detener el procesamiento.\n",
    "\n",
    "cap.release()  \n",
    "# Libera los recursos asociados al archivo de video.\n",
    "\n",
    "cv2.destroyAllWindows()  \n",
    "# Cierra todas las ventanas abiertas por OpenCV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe776f94",
   "metadata": {},
   "source": [
    "#### **9. Resultados finales**\n",
    "En esta última sección, mostramos los conteos finales de vehículos para cada carril o vía después de procesar el video completo. Este paso simplemente imprime los resultados acumulados en la consola."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000c0d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, count in enumerate(vehicle_count):  \n",
    "    # Itera sobre la lista `vehicle_count`, donde:\n",
    "    # - `i` es el índice del carril o vía.\n",
    "    # - `count` es el número total de vehículos contados para ese carril o vía.\n",
    "\n",
    "    if 2 <= i <= 6:  # Carriles de las vías 3 y 4  \n",
    "        # Comprueba si el índice corresponde a los carriles de las vías 3 y 4 (índices entre 2 y 6).\n",
    "\n",
    "        print(f\"Carril {i - 1}: {count} vehículos contados.\")  \n",
    "        # Imprime el conteo de vehículos para los carriles, ajustando el índice para que comience desde 1.\n",
    "\n",
    "    else:  \n",
    "        # Si el índice no corresponde a los carriles de las vías 3 y 4.\n",
    "\n",
    "        print(f\"Via {i + 1}: {count} vehículos contados.\")  \n",
    "        # Imprime el conteo de vehículos para las vías completas, ajustando el índice para que comience desde 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e563d134",
   "metadata": {},
   "source": [
    "## **Código completo - Vídeo Normal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6af8ed49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Via 1: 5 vehículos contados.\n",
      "Via 2: 5 vehículos contados.\n",
      "Carril 1: 10 vehículos contados.\n",
      "Carril 2: 15 vehículos contados.\n",
      "Carril 3: 4 vehículos contados.\n",
      "Carril 4: 10 vehículos contados.\n",
      "Carril 5: 6 vehículos contados.\n",
      "Via 8: 14 vehículos contados.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "video_path = 'tráfico01.mp4'\n",
    "\n",
    "lines_positions = [\n",
    "    {\"x1\": 480, \"y1\": 800, \"x2\": 570, \"y2\": 800},\n",
    "    {\"x1\": 600, \"y1\": 800, \"x2\": 700, \"y2\": 800},\n",
    "    {\"x1\": 990, \"y1\": 750, \"x2\": 1090, \"y2\": 750},\n",
    "    {\"x1\": 1280, \"y1\": 890, \"x2\": 1500, \"y2\": 890},\n",
    "    {\"x1\": 1200, \"y1\": 660, \"x2\": 1260, \"y2\": 660},\n",
    "    {\"x1\": 1450, \"y1\": 750, \"x2\": 1550, \"y2\": 750},\n",
    "    {\"x1\": 1650, \"y1\": 790, \"x2\": 1800, \"y2\": 790},\n",
    "    {\"x1\": 1500, \"y1\": 450, \"x2\": 1800, \"y2\": 450},\n",
    "]\n",
    "\n",
    "area_thresholds = [400, 500, 700, 800, 700, 700, 500, 600]\n",
    "max_vehicle_width = 400\n",
    "\n",
    "vehicle_count = [0] * len(lines_positions)\n",
    "tracked_objects = [{} for _ in range(len(lines_positions))]\n",
    "object_ids = [0] * len(lines_positions)\n",
    "object_expiry = 16\n",
    "\n",
    "def crosses_line(cx, cy, line):\n",
    "    \"\"\"Verifica si un punto cruza una línea específica.\"\"\"\n",
    "    return line[\"x1\"] <= cx <= line[\"x2\"] and abs(cy - line[\"y1\"]) <= 10\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: No se puede abrir el video.\")\n",
    "else:\n",
    "    background_subtractor = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=50, detectShadows=False)\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        fg_mask = background_subtractor.apply(gray)\n",
    "        fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5)))\n",
    "        _, fg_mask = cv2.threshold(fg_mask, 254, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        for contour in contours:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            cx, cy = x + w // 2, y + h // 2\n",
    "\n",
    "            if w > max_vehicle_width or cv2.contourArea(contour) < 500:\n",
    "                continue\n",
    "\n",
    "            for i, line in enumerate(lines_positions):\n",
    "                if crosses_line(cx, cy, line):\n",
    "                    if cv2.contourArea(contour) < area_thresholds[i]:\n",
    "                        continue\n",
    "\n",
    "                    new_object = True\n",
    "                    for obj_id in list(tracked_objects[i].keys()):\n",
    "                        prev_cx, prev_cy, last_seen = tracked_objects[i][obj_id]\n",
    "                        if abs(cx - prev_cx) < 50 and abs(cy - prev_cy) < 50:\n",
    "                            tracked_objects[i][obj_id] = (cx, cy, frame_count)\n",
    "                            new_object = False\n",
    "                            break\n",
    "\n",
    "                    if new_object:\n",
    "                        tracked_objects[i][object_ids[i]] = (cx, cy, frame_count)\n",
    "                        vehicle_count[i] += 1\n",
    "                        object_ids[i] += 1\n",
    "\n",
    "        for i, _ in enumerate(lines_positions):\n",
    "            expired_ids = [\n",
    "                obj_id for obj_id, (_, _, last_seen) in tracked_objects[i].items()\n",
    "                if frame_count - last_seen > object_expiry\n",
    "            ]\n",
    "            for obj_id in expired_ids:\n",
    "                del tracked_objects[i][obj_id]\n",
    "\n",
    "        for i, line in enumerate(lines_positions):\n",
    "            if 2 <= i <= 6:\n",
    "                label = f\"Carril {i - 1}: {vehicle_count[i]}\"\n",
    "            else:\n",
    "                label = f\"Via {i + 1}: {vehicle_count[i]}\"\n",
    "\n",
    "            cv2.line(frame, (line[\"x1\"], line[\"y1\"]), (line[\"x2\"], line[\"y2\"]), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, label, (line[\"x1\"], line[\"y1\"] - 20),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "\n",
    "        cv2.imshow(\"Vehicle Counting\", frame)\n",
    "\n",
    "        if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "for i, count in enumerate(vehicle_count):\n",
    "    if 2 <= i <= 6:\n",
    "        print(f\"Carril {i - 1}: {count} vehículos contados.\")\n",
    "    else:\n",
    "        print(f\"Via {i + 1}: {count} vehículos contados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46b8085",
   "metadata": {},
   "source": [
    "## **Código completo - Vídeo en bucle**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963fdba5",
   "metadata": {},
   "source": [
    "Este código incluye modificaciones clave para garantizar que el video se ejecute en un **bucle continuo**. A continuación, se describen los principales cambios:\n",
    "\n",
    "1. **Uso de la variable `exit_program`**:\n",
    "   - Se introduce la variable `exit_program` como una bandera para controlar si el bucle principal debe detenerse. \n",
    "   - Inicialmente, se establece en `False`, lo que permite que el programa continúe ejecutándose.\n",
    "\n",
    "2. **Bucle principal (`while not exit_program`)**:\n",
    "   - El programa se ejecuta dentro de un bucle principal que reinicia el video automáticamente cuando este llega al final.\n",
    "   - Si el usuario presiona la tecla `q`, la variable `exit_program` cambia a `True`, lo que rompe el bucle y termina la ejecución.\n",
    "\n",
    "3. **Bucle interno para procesamiento de frames**:\n",
    "   - Este bucle procesa cada frame del video utilizando OpenCV.\n",
    "   - Al llegar al final del video (`if not ret`), el bucle interno se rompe, liberando los recursos del video (`cap.release()`) y reiniciando la reproducción.\n",
    "\n",
    "4. **Salida controlada con la tecla `q`**:\n",
    "   - Dentro del bucle interno, se captura la entrada del teclado con `cv2.waitKey(30)`.\n",
    "   - Si se detecta que el usuario presionó `q`, se cambia la bandera `exit_program` a `True` y se rompe el bucle interno, lo que termina la ejecución completa del programa.\n",
    "\n",
    "Con estas modificaciones, el programa reproduce el video en bucle hasta que el usuario decide salir manualmente presionando la tecla `q`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c66fbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "\n",
    "video_path = 'tráfico01.mp4'\n",
    "\n",
    "lines_positions = [\n",
    "    {\"x1\": 480, \"y1\": 800, \"x2\": 570, \"y2\": 800},\n",
    "    {\"x1\": 600, \"y1\": 800, \"x2\": 700, \"y2\": 800},\n",
    "    {\"x1\": 990, \"y1\": 750, \"x2\": 1090, \"y2\": 750},\n",
    "    {\"x1\": 1280, \"y1\": 890, \"x2\": 1500, \"y2\": 890},\n",
    "    {\"x1\": 1200, \"y1\": 660, \"x2\": 1260, \"y2\": 660},\n",
    "    {\"x1\": 1450, \"y1\": 750, \"x2\": 1550, \"y2\": 750},\n",
    "    {\"x1\": 1650, \"y1\": 790, \"x2\": 1800, \"y2\": 790},\n",
    "    {\"x1\": 1500, \"y1\": 450, \"x2\": 1800, \"y2\": 450},\n",
    "]\n",
    "\n",
    "area_thresholds = [400, 500, 700, 800, 700, 700, 500, 600]\n",
    "max_vehicle_width = 400\n",
    "object_expiry = 16\n",
    "\n",
    "def crosses_line(cx, cy, line):\n",
    "    return line[\"x1\"] <= cx <= line[\"x2\"] and abs(cy - line[\"y1\"]) <= 10\n",
    "\n",
    "# Variable de control para salir del bucle principal\n",
    "exit_program = False\n",
    "\n",
    "while not exit_program:  # Bucle principal\n",
    "    vehicle_count = [0] * len(lines_positions)  # Reinicia el conteo de vehículos.\n",
    "    tracked_objects = [{} for _ in range(len(lines_positions))]  # Reinicia el seguimiento de objetos.\n",
    "    object_ids = [0] * len(lines_positions)  # Reinicia los identificadores únicos de objetos.\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)  # Carga el video.\n",
    "\n",
    "    if not cap.isOpened():  # Verifica si el video se cargó correctamente.\n",
    "        print(\"Error: No se puede abrir el video.\")\n",
    "        break  # Finaliza si no se puede cargar el video.\n",
    "\n",
    "    background_subtractor = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=50, detectShadows=False)\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:  # Bucle interno para procesar cada frame del video.\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:  # Si no se puede leer un frame (final del video):\n",
    "            cap.release()  # Libera el recurso del video.\n",
    "            break  # Rompe el bucle interno para reiniciar el video.\n",
    "\n",
    "        frame_count += 1\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        fg_mask = background_subtractor.apply(gray)\n",
    "        fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5)))\n",
    "        _, fg_mask = cv2.threshold(fg_mask, 254, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        for contour in contours:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            cx, cy = x + w // 2, y + h // 2\n",
    "\n",
    "            if w > max_vehicle_width or cv2.contourArea(contour) < 500:\n",
    "                continue\n",
    "\n",
    "            for i, line in enumerate(lines_positions):\n",
    "                if crosses_line(cx, cy, line):\n",
    "                    if cv2.contourArea(contour) < area_thresholds[i]:\n",
    "                        continue\n",
    "\n",
    "                    new_object = True\n",
    "                    for obj_id in list(tracked_objects[i].keys()):\n",
    "                        prev_cx, prev_cy, last_seen = tracked_objects[i][obj_id]\n",
    "                        if abs(cx - prev_cx) < 50 and abs(cy - prev_cy) < 50:\n",
    "                            tracked_objects[i][obj_id] = (cx, cy, frame_count)\n",
    "                            new_object = False\n",
    "                            break\n",
    "\n",
    "                    if new_object:\n",
    "                        tracked_objects[i][object_ids[i]] = (cx, cy, frame_count)\n",
    "                        vehicle_count[i] += 1\n",
    "                        object_ids[i] += 1\n",
    "\n",
    "        for i, _ in enumerate(lines_positions):\n",
    "            expired_ids = [\n",
    "                obj_id for obj_id, (_, _, last_seen) in tracked_objects[i].items()\n",
    "                if frame_count - last_seen > object_expiry\n",
    "            ]\n",
    "            for obj_id in expired_ids:\n",
    "                del tracked_objects[i][obj_id]\n",
    "\n",
    "        for i, line in enumerate(lines_positions):\n",
    "            if 2 <= i <= 6:\n",
    "                label = f\"Carril {i - 1}: {vehicle_count[i]}\"\n",
    "            else:\n",
    "                label = f\"Via {i + 1}: {vehicle_count[i]}\"\n",
    "\n",
    "            cv2.line(frame, (line[\"x1\"], line[\"y1\"]), (line[\"x2\"], line[\"y2\"]), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, label, (line[\"x1\"], line[\"y1\"] - 20),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "\n",
    "        cv2.imshow(\"Vehicle Counting\", frame)\n",
    "\n",
    "        key = cv2.waitKey(30) & 0xFF  # Captura la tecla presionada.\n",
    "        if key == ord('q'):  # Si se presiona 'q':\n",
    "            exit_program = True  # Cambia el estado para salir del bucle principal.\n",
    "            break  # Rompe el bucle interno para salir completamente.\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "for i, count in enumerate(vehicle_count):\n",
    "    if 2 <= i <= 6:\n",
    "        print(f\"Carril {i - 1}: {count} vehículos contados.\")\n",
    "    else:\n",
    "        print(f\"Via {i + 1}: {count} vehículos contados.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
